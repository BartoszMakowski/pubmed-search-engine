{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of indexing and searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lucene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f3a0097b048>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucene.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from org.apache.lucene.analysis.standard import StandardTokenizer, StandardAnalyzer\n",
    "from org.apache.lucene.analysis import StopFilter, TokenFilter\n",
    "from org.apache.lucene.analysis.tokenattributes import CharTermAttribute\n",
    "from org.tartarus.snowball.ext import EnglishStemmer\n",
    "from java.io import StringReader\n",
    "from org.apache.lucene.util import Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancers\n",
      "and\n",
      "their\n",
      "symptoms\n"
     ]
    }
   ],
   "source": [
    "stok = StandardTokenizer()\n",
    "sread = StringReader(\"cancers and their symptoms\")\n",
    "stok.setReader(sread)\n",
    "stok.reset()\n",
    "while stok.incrementToken():\n",
    "    print(stok.getAttribute(CharTermAttribute.class_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancers\n",
      "symptoms\n"
     ]
    }
   ],
   "source": [
    "stok = StandardTokenizer()\n",
    "sread = StringReader(\"cancers and their symptoms\")\n",
    "stok.setReader(sread)\n",
    "stok.reset()\n",
    "# while stok.incrementToken():\n",
    "#     print(stok.getAttribute(CharTermAttribute.class_))\n",
    "sfil = StopFilter(stok, StandardAnalyzer.ENGLISH_STOP_WORDS_SET)\n",
    "while sfil.incrementToken():\n",
    "    print(sfil.getAttribute(CharTermAttribute.class_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer\n",
      "symptom\n"
     ]
    }
   ],
   "source": [
    "es = EnglishStemmer()\n",
    "stok = StandardTokenizer()\n",
    "sread = StringReader(\"cancers and their symptoms\")\n",
    "stok.setReader(sread)\n",
    "stok.reset()\n",
    "# while stok.incrementToken():\n",
    "#     print(stok.getAttribute(CharTermAttribute.class_))\n",
    "sfil = StopFilter(stok, StandardAnalyzer.ENGLISH_STOP_WORDS_SET)\n",
    "while sfil.incrementToken():\n",
    "    es.setCurrent(str(sfil.getAttribute(CharTermAttribute.class_)))\n",
    "    es.stem()\n",
    "    print(es.getCurrent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from org.apache.lucene.document import Document, TextField, Field\n",
    "from org.apache.lucene.index import IndexWriter, IndexWriterConfig\n",
    "from org.apache.lucene.store import SimpleFSDirectory, RAMDirectory, FSDirectory\n",
    "from java.io import File\n",
    "from java.nio.file import Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indeksowanie bazy\n",
    "\n",
    "doc = Document()\n",
    "# ind_dir = RAMDirectory()\n",
    "path = Paths.get('index')\n",
    "ind_dir = SimpleFSDirectory(path)\n",
    "conf = IndexWriterConfig(StandardAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsowanie XML\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('../pubmed-xml/baseline/medline17n0001.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PubmedArticleSet\n"
     ]
    }
   ],
   "source": [
    "print(root.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = Paths.get('index')\n",
    "#ind_dir = SimpleFSDirectory(path)\n",
    "#conf = IndexWriterConfig(StandardAnalyzer())\n",
    "ind_wr = IndexWriter(ind_dir, conf)\n",
    "for pmed_article in root.findall('PubmedArticle'):\n",
    "    article = pmed_article.find('MedlineCitation').find('Article')\n",
    "    if article is not None and article.find('Abstract') is not None:\n",
    "        doc = Document()\n",
    "        doc.add(TextField('title', article.find('ArticleTitle').text, Field.Store.YES))\n",
    "        doc.add(TextField('abstract', article.find('Abstract').find('AbstractText').text, Field.Store.YES))\n",
    "        ind_wr.addDocument(doc)\n",
    "ind_wr.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from org.apache.lucene.index import IndexReader, LeafReader, DirectoryReader\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.queryparser.classic import QueryParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644 documents found.\n"
     ]
    }
   ],
   "source": [
    "# path = Paths.get('index')\n",
    "# ind_dir = SimpleFSDirectory(path)\n",
    "ind_reader = (DirectoryReader.open(ind_dir))\n",
    "ind_searcher = IndexSearcher(ind_reader)\n",
    "query_parser = QueryParser('abstract', StandardAnalyzer())\n",
    "query = query_parser.parse('protein')\n",
    "hits = ind_searcher.search(query, 10)\n",
    "print(str(hits.totalHits) + \" documents found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binding of calcium to a salivary phosphoprotein, protein C, and comparison with calcium binding to protein A, a related salivary phosphoprotein.\n",
      "\n",
      "\n",
      "\n",
      "Neurotrophic activity of brain extracts in forelimb regeneration of the urodele, Triturus.\n",
      "\n",
      "\n",
      "\n",
      "[Demonstration of protein kinase activities in the coronary artery of cattle].\n",
      "\n",
      "\n",
      "\n",
      "Solubility and heat stability of whey protein concentrates.\n",
      "\n",
      "\n",
      "\n",
      "Structure and assembly of the capsid of bacteriophage P22.\n",
      "\n",
      "\n",
      "\n",
      "[Investigation of rat brain prealbumins].\n",
      "\n",
      "\n",
      "\n",
      "Use of immobilized light-harvesting chlorophyll a/b protein to study the stoichiometry of its self-association.\n",
      "\n",
      "\n",
      "\n",
      "Effect of proteolytic enzymes on the binding of cobalamin to R protein and intrinsic factor. In vitro evidence that a failure to partially degrade R protein is responsible for cobalamin malabsorption in pancreatic insufficiency.\n",
      "\n",
      "\n",
      "\n",
      "[Rheology and spinning of alkaline solution of field bean protein and casein].\n",
      "\n",
      "\n",
      "\n",
      "Some properties of erythrocuprein treated by organic solvents.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score_doc in hits.scoreDocs:\n",
    "    print(ind_searcher.doc(score_doc.doc).getField('title').stringValue())\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
